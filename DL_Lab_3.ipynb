{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "00VMF-hTaZ0q"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation Function**"
      ],
      "metadata": {
        "id": "0Twf40QJboVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation functions\n",
        "def relu(inputs):\n",
        "    return torch.maximum(torch.zeros_like(inputs), inputs)\n",
        "\n",
        "def softmax(inputs):\n",
        "    exp_values = torch.exp(inputs - torch.max(inputs, dim=1, keepdim=True).values)\n",
        "    return exp_values / torch.sum(exp_values, dim=1, keepdim=True)\n",
        "\n",
        "def sigmoid(inputs):\n",
        "    return 1 / (1 + torch.exp(-inputs))"
      ],
      "metadata": {
        "id": "XH4jZtAIbrnX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dense Layer Implementation**"
      ],
      "metadata": {
        "id": "Rflxj76ZcGdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer:\n",
        "    def __init__(self, n_features, n_neurons, activation_function):\n",
        "        self.weights = torch.rand((n_features, n_neurons), requires_grad=True)\n",
        "        self.biases = torch.zeros((1, n_neurons), requires_grad=True)\n",
        "        self.activation_function = activation_function\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        weighted_sum = torch.matmul(inputs, self.weights) + self.biases\n",
        "        self.output = self.activation_function(weighted_sum)"
      ],
      "metadata": {
        "id": "vkrXlflUcTH9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorical cross-entropy loss function**"
      ],
      "metadata": {
        "id": "EZwYWWKPdIB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_crossentropy(y_pred, y_true):\n",
        "    y_pred_clipped = torch.clamp(y_pred, 1e-7, 1 - 1e-7)\n",
        "    log_likelihoods = -torch.sum(y_true * torch.log(y_pred_clipped))\n",
        "    return log_likelihoods\n"
      ],
      "metadata": {
        "id": "Rw6emzhrdVR8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 1: Using ReLU for hidden layers**"
      ],
      "metadata": {
        "id": "N9A3aP7ndwPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_section_relu():\n",
        "    torch.manual_seed(42)\n",
        "    input_data = torch.rand((1, 4), requires_grad=True)\n",
        "\n",
        "    # 3 hidden layers\n",
        "    layer1 = DenseLayer(4, 18, relu)\n",
        "    layer2 = DenseLayer(18, 18, relu)\n",
        "    layer3 = DenseLayer(18, 18, relu)\n",
        "    # output layer\n",
        "    output_layer = DenseLayer(18, 3, softmax)\n",
        "\n",
        "    # Forward pass\n",
        "    layer1.forward(input_data)\n",
        "    layer2.forward(layer1.output)\n",
        "    layer3.forward(layer2.output)\n",
        "    output_layer.forward(layer3.output)\n",
        "\n",
        "    target = torch.tensor([0, 1, 0], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "    # Computing loss\n",
        "    loss = categorical_crossentropy(output_layer.output, target)\n",
        "    accuracy = target == torch.argmax(output_layer.output, dim=1)\n",
        "\n",
        "    print(\"Section 1 - Using ReLU for hidden layers:\")\n",
        "    print(\"Final output:\", output_layer.output)\n",
        "    print(\"Categorical Cross-Entropy Loss:\", loss.item())\n",
        "    print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "QulwQqegd0q0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Section 2: Using Sigmoid for hidden layers**"
      ],
      "metadata": {
        "id": "sbEEnSEAeBL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_section_sigmoid():\n",
        "    torch.manual_seed(42)\n",
        "    input_data = torch.rand((1, 4), requires_grad=True)\n",
        "\n",
        "    # 3 hidden layers\n",
        "    layer1 = DenseLayer(4, 18, sigmoid)\n",
        "    layer2 = DenseLayer(18, 18, sigmoid)\n",
        "    layer3 = DenseLayer(18, 18, sigmoid)\n",
        "    # output layer\n",
        "    output_layer = DenseLayer(18, 3, softmax)\n",
        "\n",
        "    # Forward pass\n",
        "    layer1.forward(input_data)\n",
        "    layer2.forward(layer1.output)\n",
        "    layer3.forward(layer2.output)\n",
        "    output_layer.forward(layer3.output)\n",
        "\n",
        "    target = torch.tensor([0, 1, 0], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "    # Computing loss\n",
        "    loss = categorical_crossentropy(output_layer.output, target)\n",
        "    accuracy = target == torch.argmax(output_layer.output, dim=1)\n",
        "\n",
        "    print(\"\\nSection 2 - Using Sigmoid for hidden layers:\")\n",
        "    print(\"Final output:\", output_layer.output)\n",
        "    print(\"Categorical Cross-Entropy Loss:\", loss.item())\n",
        "    print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "0D-VuiQ6eHns"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run The Section**"
      ],
      "metadata": {
        "id": "Jpq4qcD4eJxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_section_relu()\n",
        "run_section_sigmoid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cw73tyveOq9",
        "outputId": "42c71223-5506-4535-aff1-b7c65d84cf2e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Section 1 - Using ReLU for hidden layers:\n",
            "Final output: tensor([[1.6324e-15, 0.0000e+00, 1.0000e+00]], grad_fn=<DivBackward0>)\n",
            "Categorical Cross-Entropy Loss: 16.11809539794922\n",
            "Accuracy: tensor([False, False, False])\n",
            "\n",
            "Section 2 - Using Sigmoid for hidden layers:\n",
            "Final output: tensor([[0.4800, 0.0678, 0.4522]], grad_fn=<DivBackward0>)\n",
            "Categorical Cross-Entropy Loss: 2.691300630569458\n",
            "Accuracy: tensor([ True, False,  True])\n"
          ]
        }
      ]
    }
  ]
}